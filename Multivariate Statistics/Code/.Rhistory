update.packages(ask='graphics',checkBuilt=TRUE)
update.packages(ask='graphics',checkBuilt=TRUE)
q()
mean(c(4.2,4.7,6.6,7.0,6.7,4.5,5.7,6.0,7.9,4.9,6.1,5.2))
mean(c(4.1,4.9,3.2,6.9,6.8,4.4,5.7,5.8,6.9,4.7,6.0,4.9))
x=C(5,23,25,48,17,8,4,26,11,19,14,35,29,4,23)
Y=C(80,78,60,53,85,84,73,79,81,75,68,72,58,92,65)
cor(X,Y)
x=C(5,23,25,48,17,8,4,26,11,19,14,35,29,4,23)
y=C(80,78,60,53,85,84,73,79,81,75,68,72,58,92,65)
cor(x,y)
x=c(5,23,25,48,17,8,4,26,11,19,14,35,29,4,23)
y=c(80,78,60,53,85,84,73,79,81,75,68,72,58,92,65)
cor(x,y)
r=cor(x,y)
length(y)
r*13
(r*13)/sqrt(1-r^2)
pt(0.025,13)
u=x+y
v=x-y
cor(u,v)
(r*sqrt(13))/sqrt(1-r^2)
r_1=cor(u,v)
(r_1*sqrt(13))/sqrt(1-r_1^2)
install.packages(c("broom", "bslib", "clock", "crul", "curl", "deldir", "digest", "evaluate", "flexrsurv", "future.apply", "gargle", "googledrive", "googlesheets4", "Hmisc", "httpuv", "httr", "igraph", "jsonlite", "knitr", "markdown", "MASS", "Matrix", "mice", "mvtnorm", "parallelly", "plotly", "pROC", "RcppArmadillo", "rgeos", "rmarkdown", "s2", "sass", "sf", "sp", "sys", "terra", "testthat", "treemap", "tzdb", "vctrs", "waldo", "wk"))
# Print the test results
print(result)
# Control group data
control <- c(1042, 1617, 1180, 973, 1552, 1251, 1151, 1511, 728, 1079, 951, 1319)
# Case group data
case <- c(874, 389, 612, 798, 1152, 893, 541, 741, 1064, 862, 213)
# Perform Mann-Whitney U test
result <- wilcox.test(control, case)
# Print the test results
print(result)
# Control group data
control <- c(1042, 1617, 1180, 973, 1552, 1251, 1151, 1511, 728, 1079, 951, 1319)
# Case group data
case <- c(874, 389, 612, 798, 1152, 893, 541, 741, 1064, 862, 213)
# Perform Mann-Whitney U test
result <- wilcox.test(control, case)
# Print the test results
print(result)
# Create a contingency table
smoking <- c(40, 3)
non_smoking <- c(33, 12)
contingency_table <- matrix(c(smoking, non_smoking), nrow = 2, ncol = 2, byrow = TRUE)
colnames(contingency_table) <- c("Smoker", "Non-Smoker")
rownames(contingency_table) <- c("Drinks tea", "Does not drink tea")
print(contingency_table)
# Calculate Yule's measures of association
a <- contingency_table[1, 1]
b <- contingency_table[1, 2]
c <- contingency_table[2, 1]
d <- contingency_table[2, 2]
Q <- (a * d - b * c) / (a * d + b * c)
Y <- sqrt(Q)
# Print the results
cat("Yule's Q:", Q, "\n")
cat("Yule's Y:", Y, "\n")
# Create a contingency table
smoking <- c(40, 3)
non_smoking <- c(33, 12)
contingency_table <- matrix(c(smoking, non_smoking), nrow = 2, ncol = 2, byrow = F)
colnames(contingency_table) <- c("Smoker", "Non-Smoker")
rownames(contingency_table) <- c("Drinks tea", "Does not drink tea")
print(contingency_table)
# Calculate Yule's measures of association
a <- contingency_table[1, 1]
b <- contingency_table[1, 2]
c <- contingency_table[2, 1]
d <- contingency_table[2, 2]
Q <- (a * d - b * c) / (a * d + b * c)
Y <- sqrt(Q)
# Print the results
cat("Yule's Q:", Q, "\n")
cat("Yule's Y:", Y, "\n")
install.packages(c("bookdown", "bslib", "cpp11", "curl", "dbplyr", "deSolve", "digest", "fontawesome", "forestplot", "fs", "future", "gargle", "ggplot2", "glmnet", "Gmisc", "gtable", "haven", "htmltools", "httr", "igraph", "jsonlite", "labeling", "lme4", "markdown", "Matrix", "MatrixModels", "mvtnorm", "nlme", "openssl", "pan", "patchwork", "pkgload", "pROC", "processx", "prodlim", "progressr", "promises", "purrr", "quantreg", "raster", "rbibutils", "Rcpp", "RcppArmadillo", "Rdpack", "readxl", "recipes", "rematch", "rgeos", "rmarkdown", "rstudioapi", "sass", "sf", "shiny", "testthat", "tinytex", "units", "uuid", "viridis", "wk", "xfun", "xml2"))
install.packages("quarto")
quarto::quarto_version()
which irkernel
which irkernel
getwd()
setwd("~/Multivariate Statistics/Code")
# Principal Component Calculation from Covariance Matrix
CovMat<-matrix(c(1,-2,0,-2,5,0,0,0,2),3,3)  # Cov(X)
r<-eigen(CovMat)
v<-r$vectors        # v=[e1:e2:...:eP]
# Rotational Matrix Y=XA'
A=t(v)
# Variance explained by Principal Component
lam<-r$values
PrnCovMat<-t(v)%*%CovMat%*%v                # Cov(Y)
lam
PrnCovMat
data=data(apples)
data=apples
data(apples)
data(basketball)
data(turtles)
#########################################################
# Principal Component Calculation from Data
# Problem 8.4
# Load the dataset and convert to dataframe
#########################################################
library(Flury)
data(turtles)
library(Flury)
data=apples
data=data("apples")
data
data("apples")
str(apples)
pca_apples=prcomp(data=apples,scale. =TRUE, center=TRUE)
pca_apples=prcomp(data=apples, center=TRUE,scale.=TRUE)
pca_apples=prcomp(data=apples, center=TRUE,scale.=TRUE)
pca_apples=prcomp(apples, center=TRUE,scale.=TRUE)
apples
str(apples)
pca_apples=prcomp(apples, center=TRUE,scale.=TRUE)
apples[,-1]=apples
apples[,-c(1)]=apples
data=apples[,-1]
data
apples[apples$Rootstock==1]
apples[apples[,1]==1]
apples[,1]
apples[,1]==1
apples[apples[,1]==1]
apples[,1]==1
apples[[apples[,1]==1]]
apples[apples[,1]==1,]
pca_apples
library(Flury)
data("apples")
str(apples)
data=apples[apples[,1]==1,]
pca_apples=prcomp(data, center=TRUE,scale.=TRUE)
pca_apples
data=data[,-1]
pca_apples=prcomp(data, center=TRUE,scale.=TRUE)
pca_apples
pca_apples_mat=as.matrix(pca_apples$rotation)
pca_apples_mat
apples_var_eigen=(pca_apples$sdev)^2
apples_var_eigen
summary(pca_apples)
plot(apples_var_eigen)
plot(apples_var_eigen,type = 'b')
turtles
# Principal Component Calculation from Covariance Matrix
CovMat<-matrix(c(1,-2,0,-2,5,0,0,0,2),3,3)  # Cov(X)
r<-eigen(CovMat)
v<-r$vectors        # v=[e1:e2:...:eP]
# Rotational Matrix Y=XA'
A=t(v)
# Variance explained by Principal Component
lam<-r$values
PrnCovMat<-t(v)%*%CovMat%*%v                # Cov(Y)
# Correlation of different Variables (Xs) on Principal Component (Ys)
CorrBetYandX<-t(v)%*%CovMat/(sqrt(lam)%o%sqrt(diag(CovMat)))
CorrBetYandX
as.table(CorrBetYandX)
#########################################################################
dataMat=matrix(c(26.4,13.2,6.25,2.19,1.26,2.85,2.86,9.58,23,15,7.05,2.6,1.44,3.15,2.69,9.65,34.9,20.6,9.64,3.74,1.73,4.21,2.5,8.42,34.2,19.8,9.1,3.68,1.89,4.2,2.47,9.45,27.5,16.2,7.27,3.15,1.44,3.43,2.3,8.96,26.3,14.5,6.39,3.04,1.87,3.01,2.09,12.8,25,14.6,6.35,3.14,1.25,3.33,2.02,8.55),byrow = TRUE, nrow = 8,ncol=7)
print(dataMat)
dataMatPCA=prcomp(dataMat,center = TRUE,scale. = TRUE)
print(dataMatPCA)
pc1=dataMatPCA$x[,1]
pc1
dataMatPCA
dataMatPCA$x
dataMatPcaVariance=(dataMatPCA$sdev)^2    #Eigen Values of correlation matrix
print(dataMatPcaVariance)
Percentage=round(100*((dataMatPcaVariance))/sum(dataMatPcaVariance),2)
print(Percentage)
cumPercentage=100*(cumsum(dataMatPcaVariance))/sum(dataMatPcaVariance)
print(cumPercentage)
plot(dataMatPcaVariance,type = 'b')                  #Scree plot
plot(pc1,pc2,xlab=paste(c('PC axis 1',' ( ',Percentage[1],'% )'), collapse=''), ylab=paste(c('PC axis 2',' ( ',Percentage[2],'% )'), collapse=''), xlim=c(min(pc1)-.1*abs(min(pc1)), max(pc1)+.1*abs(max(pc1))), ylim=c(min(pc2)-.1*abs(min(pc2)), max(pc2)+.1*abs(max(pc2))))
names1 = c("1","2","3","4","5","6","7")
text(pc1,pc2,labels=names1,adj = c(0.3,-.8))
pc2=dataMatPCA$x[,2]
dataMatPcaVariance=(dataMatPCA$sdev)^2    #Eigen Values of correlation matrix
print(dataMatPcaVariance)
Percentage=round(100*((dataMatPcaVariance))/sum(dataMatPcaVariance),2)
print(Percentage)
cumPercentage=100*(cumsum(dataMatPcaVariance))/sum(dataMatPcaVariance)
print(cumPercentage)
plot(dataMatPcaVariance,type = 'b')                  #Scree plot
plot(pc1,pc2,xlab=paste(c('PC axis 1',' ( ',Percentage[1],'% )'), collapse=''), ylab=paste(c('PC axis 2',' ( ',Percentage[2],'% )'), collapse=''), xlim=c(min(pc1)-.1*abs(min(pc1)), max(pc1)+.1*abs(max(pc1))), ylim=c(min(pc2)-.1*abs(min(pc2)), max(pc2)+.1*abs(max(pc2))))
names1 = c("1","2","3","4","5","6","7")
text(pc1,pc2,labels=names1,adj = c(0.3,-.8))
biplot(dataMatPCA)
f1<-dataMatPCA$sdev[1]*dataMatPCA$rotation[,1]
f2<-dataMatPCA$sdev[2]*dataMatPCA$rotation[,2]
plot(f1,f2,xlab="Factor 1", ylab="Factor 2",
xlim=c(min(f1)-.1*abs(min(f1)), max(f1)+.1*abs(max(f1))), ylim=c(min(f2)-.1*abs(min(f2)), max(f2)+.1*abs(max(f2))))
names2 = c("A","B","C","D","E","F","G","H")
text(f1,f2,labels=names2,adj = c(0.3,-.8))
biplot(dataMatPCA)
r<-eigen(CovMat)
r
# Variance explained by Principal Component
lam<-r$values
PrnCovMat<-t(v)%*%CovMat%*%v                # Cov(Y)
lam
PrnCovMat
StockMat<-as.matrix(Stock)
#########################################################################
# # Standerdizing the data
# n<-nrow(StockMat)
# p<-ncol(StockMat)
# StockMean<-colMeans(StockMat)
# DHalf<-sqrt((diag(var(StockMat))))
# StdStockMat<-(StockMat-t(matrix(rep(StockMean,n),p,n)))/t(matrix(rep(DHalf,n),p,n))
# # Variance of Standarized Data and Correlation of Original Data are same
# StdStockMatVar=var(StdStockMat)
#########################################################################
StockMatCor=cor(StockMat)   #Correlation Matrix
print(StockMatCor)
# We will do the Principal Component Analysis by "prcomp" method
StockMatPCA <- prcomp(StockMat,center = TRUE,scale. = TRUE)   #PCA on standardized data by centering and scaling
print(StockMatPCA)
StockMatPcaVariance=(StockMatPCA$sdev)^2    #Eigen Values of correlation matrix
print(StockMatPcaVariance)
plot(StockMatPcaVariance,type="b")
cumPercentage=100*(cumsum(StockMatPcaVariance))/sum(StockMatPcaVariance)
print(cumPercentage)
#########################################################################
dataMat=matrix(c(26.4,13.2,6.25,2.19,1.26,2.85,2.86,9.58,23,15,7.05,2.6,1.44,3.15,2.69,9.65,34.9,20.6,9.64,3.74,1.73,4.21,2.5,8.42,34.2,19.8,9.1,3.68,1.89,4.2,2.47,9.45,27.5,16.2,7.27,3.15,1.44,3.43,2.3,8.96,26.3,14.5,6.39,3.04,1.87,3.01,2.09,12.8,25,14.6,6.35,3.14,1.25,3.33,2.02,8.55),byrow = TRUE, nrow = 8,ncol=7)
print(dataMat)
dataMatPCA=prcomp(dataMat,center = TRUE,scale. = TRUE)
biplot(dataMatPCA)
f1<-dataMatPCA$sdev[1]*dataMatPCA$rotation[,1]
f2<-dataMatPCA$sdev[2]*dataMatPCA$rotation[,2]
plot(f1,f2,xlab="Factor 1", ylab="Factor 2",
xlim=c(min(f1)-.1*abs(min(f1)), max(f1)+.1*abs(max(f1))), ylim=c(min(f2)-.1*abs(min(f2)), max(f2)+.1*abs(max(f2))))
factanal(dataMat[,-c(3,4)],2)
# =======================================================
# Factor Analysis
# =======================================================
Stock=read.csv("Stock Price Data.csv", header=F)
StockMat<-as.matrix(Stock)
n<-nrow(StockMat)
p<-ncol(StockMat)
# =======================================================
# Factor Analysis by PCA
# =======================================================
# We will do the Principal Component Analysisby "prcomp" method
StdStockMatPCA <- prcomp(StockMat,center = TRUE,scale. = TRUE)
print(StdStockMatPCA)
StdStockMatFactLoad<-StdStockMatPCA$rotation*t(matrix(rep(StdStockMatPCA$sdev,p),p,p))  #[\sqrt(\lambda_1)e_1:...:\sqrt(\lambda_p)e_p]
print(StdStockMatFactLoad)  #Loadings on factors,i.e., full L matrix
StdStockMatSpecVar<-1-t(apply(StdStockMatFactLoad^2,1,cumsum))  #Calculating diagonal elments of specific variance matrix taking groups of factors at a time
print(StdStockMatSpecVar) #First column is the diagonal elements of \Psi when only one factor is considered, second column is the diagonal elements of \Psi when two factors are considered and so on
CumProp=(cumsum(StdStockMatPCA$sdev^2))/sum(StdStockMatPCA$sdev^2)
print(CumProp)  #Cumulative Percentages of variations explained by factors
Res1=cor(StockMat)-StdStockMatFactLoad[,1]%*%t(StdStockMatFactLoad[,1])-diag(StdStockMatSpecVar[,1])
print(Res1) #S-LL' -\Psi, when one factor is considered
sum(Res1*Res1)
Res2=cor(StockMat)-StdStockMatFactLoad[,c(1,2)]%*%t(StdStockMatFactLoad[,c(1,2)])-diag(StdStockMatSpecVar[,2])
print(Res2) #S-LL' -\Psi, when two factors are considered
sum(Res2*Res2)
Res3=cor(StockMat)-StdStockMatFactLoad[,c(1,2,3)]%*%t(StdStockMatFactLoad[,c(1,2,3)])-diag(StdStockMatSpecVar[,3])
print(Res3) #S-LL' -\Psi, when three factors are considered
sum(Res3*Res3)
# =======================================================
# Factor Analysis by MLE
# =======================================================
StockMatFA <- factanal(StockMat,factors = 2,scores = "none")
# [n-1-(2p+4m+5)/6]ln[|LL'+\shi|/|Sn|] follows \Chi^2 wit df=[(p-m)^2-p-m]/2
print(StockMatFA)
# \shi
StockMatSpVr<-1-t(apply(StockMatFA$loadings^2,1,cumsum))
print(diag(StockMatSpVr[,2]))
# R-LL'-\shi
Res2M<-cor(StockMat)-StockMatFA$loadings[,c(1,2)]%*%t(StockMatFA$loadings[,c(1,2)])-diag(StockMatSpVr[,2])
print(Res2M)
sum(Res2M*Res2M)
# Test for m=2
# [n-1-(2p+4m+5)/6]ln[|LL'+\shi|/|Sn|] follows \Chi^2 wit df=[(p-m)^2-p-m]/2
m=2
den=det(cor(StockMat))
num=det(StockMatFA$loadings[,c(1,2)]%*%t(StockMatFA$loadings[,c(1,2)])+diag(StockMatSpVr[,2]))
ts=(n-1-(2*p+4*m+5)/6)*log(num/den)
df=((p-m)^2-p-m)/2
(pval=pchisq(ts,df,lower.tail = FALSE))
#########################################################################
# Standerdizing the data
n<-nrow(StockMat)
p<-ncol(StockMat)
StockMean<-colMeans(StockMat)
DHalf<-sqrt((diag(var(StockMat))))
StdStockMat<-(StockMat-t(matrix(rep(StockMean,n),p,n)))/t(matrix(rep(DHalf,n),p,n))
# Factor Score by Regression L_z'R^{-1}z'
StockMatFA_Score_Reg<-t(StockMatFA$loadings)%*%solve(cor(StockMat))%*%t(StdStockMat)
plot(StockMatFA_Score_Reg[1,],StockMatFA_Score_Reg[2,])
StockMatFA_reg <- factanal(StockMat,factors = 2,scores = "regression")
# Factor Score by Weighted Least Square (L_z'\shi^{-1}L_z)^{-1}L_z'\shi^{-1}z'
StockMatFA_Score_WLS<-solve(t(StockMatFA$loadings)%*%solve(cor(StockMat))%*%StockMatFA$loadings)%*%t(StockMatFA$loadings)%*%solve(cor(StockMat))%*%t(StdStockMat)
plot(StockMatFA_Score_WLS[1,],StockMatFA_Score_WLS[2,])
StockMatFA_wls <- factanal(StockMat,factors = 2,scores = "Bartlett")
