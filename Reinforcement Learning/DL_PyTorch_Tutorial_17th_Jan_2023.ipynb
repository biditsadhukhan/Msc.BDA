{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVrB3bXfiBgW"
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BZMYdNa8tW1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpG2pR6GiTVY"
   },
   "source": [
    "**Defining a torch tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brc1tqmFiA5e",
    "outputId": "60af8b32-1345-46ab-8b72-d724ba88fc60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.tensor([1,2,3]) # long by default\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2-zlsu8isdf",
    "outputId": "935a9c39-044d-449f-b6b1-3ce52e40d80c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other tensor types\n",
    "state = torch.tensor([1,2,3], dtype=torch.float)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHH6SkRdi16d",
    "outputId": "cefa51d6-5e87-4362-dcc4-daa3bbe833fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-dimenstional tensors\n",
    "state = torch.Tensor([[1,2,3], [4,5,6], [7,8,9]]) # float32 by default\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEEOShKOm1my",
    "outputId": "ab013e22-8ebd-4162-eec1-fff5946042d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# A couple more useful torch functions to initialize tensors\n",
    "print(torch.zeros((2,2)))\n",
    "print(torch.ones((3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDxQByS1iZqE"
   },
   "source": [
    "**Some useful tensor properties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onv5dRXEiYni",
    "outputId": "24a4b2c6-efb8-4cda-f09d-f1826e08961c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "torch.float32\n",
      "torch.Size([3, 3])\n",
      "cpu\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(state)\n",
    "print(state.dtype) # the type of elements in the tensor, eg: long, float32, etc.\n",
    "print(state.shape) # the shape of the tensor\n",
    "print(state.device) # the device the tensor is on: CPU or GPU\n",
    "print(state.grad) # the gradient of the tensor, more on this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-c4lDYTGjgjd"
   },
   "source": [
    "**Side note: How to check if I have a GPU?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tz4_svYGifnm",
    "outputId": "355f1a15-807a-4224-de8a-430d6de4187f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not using a GPU right now\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8BYqWNRjufH"
   },
   "source": [
    "**Useful tensor operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6Nvp8yGjnY1",
    "outputId": "f51c259f-39ab-46e7-b6a5-a24f56cf2ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.)\n",
      "tensor(5.)\n",
      "tensor(9.)\n"
     ]
    }
   ],
   "source": [
    "print(state.sum()) # Also torch.sum(state)\n",
    "print(state.mean()) # Also torch.mean(state)\n",
    "print(state.max()) # Also torch.max(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlJ7Lf8vlQef"
   },
   "source": [
    "You can also do these operations across specific dimensions. Here is an example with `sum` but you can do the same things with other operations like `max` and `mean` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gENhh_xlWJs",
    "outputId": "4accb84a-9c3b-4865-ff38-a51724b8ba70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12., 15., 18.])\n",
      "tensor([ 6., 15., 24.])\n",
      "tensor([ 6., 15., 24.])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# summing with dim=0 collapses 0th dimension aka row dimension and sums the columns\n",
    "print(state.sum(dim=0)) \n",
    "# summing with dim=1 collapses the 1st dimension aka column dimension and sums the rows\n",
    "print(state.sum(dim=1)) \n",
    "# summing with dim=-1 collapses the last dimension aka column dimension and sums the rows\n",
    "print(state.sum(dim=-1)) \n",
    "# Here is a more telling example\n",
    "print(torch.ones((3,4,5)).sum(-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pVphnV5k5vk"
   },
   "source": [
    "You can add and subtract tensors and multiply them as you do with `numpy` arrays. You can also do broadcast operations as you would with numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQfd4m2Ekzbj",
    "outputId": "9f004c4a-7a76-4363-dc70-7a54a9009001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.],\n",
      "        [14., 16., 18.]])\n",
      "*****************\n",
      "tensor([[ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(state * 2) # every element is multiplied by 2\n",
    "print(\"*****************\")\n",
    "print(state + 2) # 2 is added to every element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcYhm0H3nhAj"
   },
   "source": [
    "**Element-wise multiplication and matrix multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN9H0U3ZnnXo",
    "outputId": "119f3b8f-91c8-44f8-a5f6-4f5ba13ed091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10., 18.])\n",
      "tensor(32.)\n",
      "tensor([6., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.Tensor([1,2,3]) # 1x3\n",
    "x2 = torch.Tensor([4,5,6]) # 1x3\n",
    "x3 = torch.ones((3,3)) # 3x3\n",
    "\n",
    "print(x1 * x2) # element-wise multiplication\n",
    "print(x1.dot(x2)) # vector dot product\n",
    "print(x1.matmul(x3)) # matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG8B7uRjog0n"
   },
   "source": [
    "**Reshaping Torch tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--A01Nc0oRcZ",
    "outputId": "0b374415-03c1-4cde-db92-b1971a735ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([5, 2, 6])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((3,4,5))\n",
    "y = torch.ones((2,3))\n",
    "\n",
    "print(x.reshape(20,3).shape)\n",
    "print(x.reshape(3, -1).shape) # torch infers what should come in the -1 position\n",
    "print(x.reshape(5,2,-1).shape)\n",
    "print(y.T.shape) # NOT the same as y.reshape(3,2)\n",
    "print(x.transpose(-1,1).shape) # allows you to swapaxes in multi-dimensional tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9kipjv3p33E"
   },
   "source": [
    "**Some more useful methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDNGlkZIomxU",
    "outputId": "96fe6e54-5500-414d-95c7-5b7fa3a68df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7500)\n",
      "tensor([0.7311, 0.8808, 0.9526, 0.9820])\n",
      "tensor([[0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1]])\n",
      "tensor([[0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.Tensor([1,2,3,4])\n",
    "x2 = torch.Tensor([2,3,5,7])\n",
    "\n",
    "print(F.mse_loss(x1, x2)) # calculates MSE loss between x1 and x2\n",
    "print(torch.sigmoid(x1)) # applies the sigmoid function on the given tensor\n",
    "print(F.one_hot(x1.long(), 5)) # converts the tensor to one-hot\n",
    "print(F.one_hot(x1.long(), 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHcAngX_rAAb"
   },
   "source": [
    "**Tensors with gradients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBnEUETYqfHp",
    "outputId": "20fc30c9-2280-42a5-815d-a2a70582391a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n",
      "True\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "state = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "print(state.grad) # state has no gradient now\n",
    "print(state.requires_grad) # torch is not tracking the gradient either\n",
    "state.requires_grad = True # this will tell torch to track the gradient of state\n",
    "print(state.requires_grad)\n",
    "print(state.grad) # but still no gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzYUnsdVsCWD",
    "outputId": "b43be1c0-ff04-445d-af00-cb082b2cbe4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 25 # some random target\n",
    "prediction = state.sum()\n",
    "loss = (target - prediction) **2 # by the way, ** is also a broadcast operation\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgeaAljatB8E",
    "outputId": "ad598812-f88a-453b-9db4-33a6be1a896c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8., -8., -8.],\n",
       "        [-8., -8., -8.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "state.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "558T1shHtgQz"
   },
   "source": [
    "We can now use this gradient to perform an update on `state` using gradient descent or any other fancy optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AW6I_SXt-P9"
   },
   "source": [
    "**The torch `nn` module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsgDpBQ6tSOF"
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Linear(10,5) # encapsulates a weight and a bias and is tracking gradients by default\n",
    "    self.layer2 = nn.Linear(5, 1) \n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.layer1(x) # self.layer(x) performs w.T.matmul(x) + b\n",
    "    out = nn.ReLU()(out)\n",
    "    return self.layer2(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhKL05N9ulaW",
    "outputId": "ff603933-1108-4ef8-cb02-93d894e93b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10]) torch.Size([5])\n",
      "tensor([[-0.0836],\n",
      "        [-0.0836],\n",
      "        [-0.0836],\n",
      "        [-0.0836]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "print(model.layer1.weight.shape, model.layer1.bias.shape)\n",
    "input = torch.ones(4, 10) # shape is batchsize x dimension\n",
    "out = model(input) # same as model.forward(input)\n",
    "print(out)\n",
    "print(out.shape) # batchsize x output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TjFxF1wwaFY"
   },
   "source": [
    "Let's add a simple loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiyCD05rvRdF",
    "outputId": "e6f2c655-b4ba-4a0d-df3a-b0cbf20d356c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4035, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "target = torch.tensor([0.4, 0.2, 0.99, 0.3]).reshape(-1, 1) # random target\n",
    "loss = F.mse_loss(out, target) # MSE loss\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPqqJhGFxwRB",
    "outputId": "41d6c4cc-4f69-42f6-edb2-79f7ea49c8f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1318, -0.0576, -0.3030, -0.2118,  0.2717, -0.1217,  0.0581, -0.2497,\n",
      "         -0.2116,  0.2607],\n",
      "        [ 0.2519,  0.2266, -0.0837,  0.0837,  0.0498, -0.1639,  0.1967,  0.0892,\n",
      "          0.2818,  0.2643],\n",
      "        [ 0.2002, -0.2317, -0.1012,  0.1545, -0.1425, -0.1672, -0.2687, -0.0745,\n",
      "          0.1760,  0.2588],\n",
      "        [ 0.1746, -0.2022, -0.0185,  0.2798, -0.0306,  0.2052, -0.2881,  0.0842,\n",
      "          0.2125,  0.2463],\n",
      "        [ 0.3013,  0.1859, -0.0012,  0.0886, -0.0355,  0.1531, -0.2281, -0.2515,\n",
      "          0.2611,  0.2024]], requires_grad=True) Parameter containing:\n",
      "tensor([ 0.0390,  0.1265, -0.1221, -0.0808,  0.0080], requires_grad=True)\n",
      "*************************************\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(model.layer1.weight, model.layer1.bias) # no gradient yet\n",
    "print(\"*************************************\")\n",
    "print(model.layer1.weight.grad, model.layer1.bias.grad) # no gradient yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zkb0H-XGyC5V"
   },
   "source": [
    "Before we get the gradient, let's define an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceV9twblyG0y"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1) # this learning rate is extremely high for Adam btw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fp1nMUOyg0w",
    "outputId": "e2a02bfa-98a3-4421-a1f1-71abc977b14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.2292,  0.2292,  0.2292,  0.2292,  0.2292,  0.2292,  0.2292,  0.2292,\n",
      "          0.2292,  0.2292],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.4020,  0.4020,  0.4020,  0.4020,  0.4020,  0.4020,  0.4020,  0.4020,\n",
      "          0.4020,  0.4020],\n",
      "        [-0.4448, -0.4448, -0.4448, -0.4448, -0.4448, -0.4448, -0.4448, -0.4448,\n",
      "         -0.4448, -0.4448]]) tensor([ 0.0000,  0.2292,  0.0000,  0.4020, -0.4448])\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad() # clears the gradients (they're cleared anyway at this point)\n",
    "loss.backward() # calculates the gradients\n",
    "print(model.layer1.weight.grad, model.layer1.bias.grad) # now we have gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vv1m17ay7An"
   },
   "source": [
    "But we still haven't updated the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxZiQ-VSyslp",
    "outputId": "7cd3161f-66a7-4ab4-f6dd-7932539d7eeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1318, -0.0576, -0.3030, -0.2118,  0.2717, -0.1217,  0.0581, -0.2497,\n",
      "         -0.2116,  0.2607],\n",
      "        [ 0.2519,  0.2266, -0.0837,  0.0837,  0.0498, -0.1639,  0.1967,  0.0892,\n",
      "          0.2818,  0.2643],\n",
      "        [ 0.2002, -0.2317, -0.1012,  0.1545, -0.1425, -0.1672, -0.2687, -0.0745,\n",
      "          0.1760,  0.2588],\n",
      "        [ 0.1746, -0.2022, -0.0185,  0.2798, -0.0306,  0.2052, -0.2881,  0.0842,\n",
      "          0.2125,  0.2463],\n",
      "        [ 0.3013,  0.1859, -0.0012,  0.0886, -0.0355,  0.1531, -0.2281, -0.2515,\n",
      "          0.2611,  0.2024]], requires_grad=True) Parameter containing:\n",
      "tensor([ 0.0390,  0.1265, -0.1221, -0.0808,  0.0080], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layer1.weight, model.layer1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "252ndEA5zSUp"
   },
   "source": [
    "Now let's update the weights using the optimizer, As we can see below, the weight has now been updated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2kCjrgXzZ5B",
    "outputId": "ad26227b-d4a2-49c1-f691-e6aae72735d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1318, -0.0576, -0.3030, -0.2118,  0.2717, -0.1217,  0.0581, -0.2497,\n",
      "         -0.2116,  0.2607],\n",
      "        [ 0.1519,  0.1266, -0.1837, -0.0163, -0.0502, -0.2639,  0.0967, -0.0108,\n",
      "          0.1818,  0.1643],\n",
      "        [ 0.2002, -0.2317, -0.1012,  0.1545, -0.1425, -0.1672, -0.2687, -0.0745,\n",
      "          0.1760,  0.2588],\n",
      "        [ 0.0746, -0.3022, -0.1185,  0.1798, -0.1306,  0.1052, -0.3881, -0.0158,\n",
      "          0.1125,  0.1463],\n",
      "        [ 0.4013,  0.2859,  0.0988,  0.1886,  0.0645,  0.2531, -0.1281, -0.1515,\n",
      "          0.3611,  0.3024]], requires_grad=True) Parameter containing:\n",
      "tensor([ 0.0390,  0.0265, -0.1221, -0.1808,  0.1080], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print(model.layer1.weight, model.layer1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CoIIM8Azsip"
   },
   "source": [
    "**A general PyTorch recipe:**\n",
    "\n",
    "\n",
    "1.   Create a model class\n",
    "2.   Get your training and evaluation data\n",
    "3.   Set up an optimizer\n",
    "4.   Perform forward passes with training data\n",
    "5. `optimizer.zero_grad()`\n",
    "6. `loss.backward()`\n",
    "7. `optimizer.step()`\n",
    "8. After few steps of training, evaluate on evaluation data\n",
    "9. Repeat until loss doesn't decrease or evaluation performance starts to fall off\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeZxbcJM0NVB"
   },
   "source": [
    "**Saving and loading models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNArbnlQKzhC",
    "outputId": "a7d150c7-f751-4613-8e56-cbdf82241004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[ 0.1318, -0.0576, -0.3030, -0.2118,  0.2717, -0.1217,  0.0581, -0.2497,\n",
       "                       -0.2116,  0.2607],\n",
       "                      [ 0.1519,  0.1266, -0.1837, -0.0163, -0.0502, -0.2639,  0.0967, -0.0108,\n",
       "                        0.1818,  0.1643],\n",
       "                      [ 0.2002, -0.2317, -0.1012,  0.1545, -0.1425, -0.1672, -0.2687, -0.0745,\n",
       "                        0.1760,  0.2588],\n",
       "                      [ 0.0746, -0.3022, -0.1185,  0.1798, -0.1306,  0.1052, -0.3881, -0.0158,\n",
       "                        0.1125,  0.1463],\n",
       "                      [ 0.4013,  0.2859,  0.0988,  0.1886,  0.0645,  0.2531, -0.1281, -0.1515,\n",
       "                        0.3611,  0.3024]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([ 0.0390,  0.0265, -0.1221, -0.1808,  0.1080])),\n",
       "             ('layer2.weight',\n",
       "              tensor([[-0.2829, -0.1061,  0.1022, -0.2615,  0.4999]])),\n",
       "             ('layer2.bias', tensor([0.2259]))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvdKgw2G0RK0",
    "outputId": "2a90283b-fe45-4174-9e97-b0187c32107e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\") # saving the model\n",
    "new_model = MyModel()\n",
    "new_model.load_state_dict(torch.load(\"model.pt\")) # loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb1rs7oN1Au9"
   },
   "source": [
    "A couple more useful torch modules that you might find useful for assignments 2 and 3 are `nn.Sequential` and the `Conv2D` module. Check these out in the [PyTorch documentation](https://pytorch.org/docs/stable/index.html)!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
