{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYTIg6X3e8U1",
    "outputId": "c85c461e-2cbe-4e18-8776-47efad03e4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "{(0, 1): (0, 1), (1, 2): (1, 0), (2, 1): (0, 1), (0, 0): (0, 1), (3, 1): None, (2, 0): (0, 1), (3, 0): (-1, 0), (0, 2): (1, 0), (2, 2): (1, 0), (1, 0): (1, 0), (3, 2): None}\n",
      "[['>', '>', '>', '.'], ['^', None, '^', '.'], ['^', '>', '^', '<']]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def vector_add(a, b):\n",
    "    \"\"\"Vector addition.\"\"\"\n",
    "    return (a[0] + b[0], a[1] + b[1])\n",
    "\n",
    "def turn_right(orientation):\n",
    "    \"\"\"Turn the orientation to the right.\"\"\"\n",
    "    return (orientation[1], -orientation[0])\n",
    "\n",
    "def turn_left(orientation):\n",
    "    \"\"\"Turn the orientation to the left.\"\"\"\n",
    "    return (-orientation[1], orientation[0])\n",
    "\n",
    "def update(obj, **kwargs):\n",
    "    \"\"\"Update object attributes.\"\"\"\n",
    "    obj.__dict__.update(kwargs)\n",
    "\n",
    "class MDP:\n",
    "    def __init__(self, init, actlist, terminals, gamma=0.9):\n",
    "        self.init = init\n",
    "        self.actlist = actlist\n",
    "        self.terminals = terminals\n",
    "        self.gamma = gamma\n",
    "        self.states = set()\n",
    "        self.reward = {}\n",
    "\n",
    "    def R(self, state):\n",
    "        \"\"\"Return a numeric reward for this state.\"\"\"\n",
    "        return self.reward[state]\n",
    "\n",
    "    def T(self, state, action):\n",
    "        \"\"\"Transition model. From a state and an action, return a list\n",
    "        of (result-state, probability) pairs.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"Set of actions that can be performed in this state.\"\"\"\n",
    "        if state in self.terminals:\n",
    "            return [None]\n",
    "        else:\n",
    "            return self.actlist\n",
    "\n",
    "class GridMDP(MDP):\n",
    "    def __init__(self, grid, terminals, init=(0, 0), gamma=0.9):\n",
    "        grid.reverse()\n",
    "        super().__init__(init, actlist=[(1, 0), (0, 1), (-1, 0), (0, -1)], terminals=terminals, gamma=gamma)\n",
    "        self.grid = grid\n",
    "        self.rows = len(grid)\n",
    "        self.cols = len(grid[0])\n",
    "        for x in range(self.cols):\n",
    "            for y in range(self.rows):\n",
    "                self.reward[(x, y)] = grid[y][x]\n",
    "                if grid[y][x] is not None:\n",
    "                    self.states.add((x, y))\n",
    "\n",
    "    def T(self, state, action):\n",
    "        if action is None:\n",
    "            return [(0.0, state)]\n",
    "        else:\n",
    "            return [(0.8, self.go(state, action)),\n",
    "                    (0.1, self.go(state, turn_right(action))),\n",
    "                    (0.1, self.go(state, turn_left(action)))]\n",
    "\n",
    "    def go(self, state, direction):\n",
    "        state1 = vector_add(state, direction)\n",
    "        return state1 if state1 in self.states else state\n",
    "\n",
    "    def to_grid(self, mapping):\n",
    "        return list(reversed([[mapping.get((x, y), None) for x in range(self.cols)] for y in range(self.rows)]))\n",
    "\n",
    "    def to_arrows(self, policy):\n",
    "        chars = {(1, 0): '>', (0, 1): '^', (-1, 0): '<', (0, -1): 'v', None: '.'}\n",
    "        return self.to_grid({s: chars[a] for s, a in policy.items()})\n",
    "\n",
    "def value_iteration(mdp, epsilon=0.001):\n",
    "    U1 = {s: 0 for s in mdp.states}\n",
    "    R, T, gamma = mdp.R, mdp.T, mdp.gamma\n",
    "    while True:\n",
    "        U = U1.copy()\n",
    "        delta = 0\n",
    "        for s in mdp.states:\n",
    "            U1[s] = R(s) + gamma * max([sum([p * U[s1] for (p, s1) in T(s, a)]) for a in mdp.actions(s)])\n",
    "            delta = max(delta, abs(U1[s] - U[s]))\n",
    "        if delta < epsilon * (1 - gamma) / gamma:\n",
    "             return U\n",
    "\n",
    "def best_policy(mdp, U):\n",
    "    pi = {}\n",
    "    for s in mdp.states:\n",
    "        pi[s] = max(mdp.actions(s), key=lambda a: expected_utility(a, s, U, mdp))\n",
    "    return pi\n",
    "\n",
    "def expected_utility(a, s, U, mdp):\n",
    "    return sum([p * U[s1] for (p, s1) in mdp.T(s, a)])\n",
    "\n",
    "def policy_iteration(mdp):\n",
    "    U = {s: 0 for s in mdp.states}\n",
    "    pi = {s: random.choice(mdp.actions(s)) for s in mdp.states}\n",
    "    while True:\n",
    "        U = policy_evaluation(pi, U, mdp)\n",
    "        unchanged = True\n",
    "        for s in mdp.states:\n",
    "            a = max(mdp.actions(s), key=lambda a: expected_utility(a, s, U, mdp))\n",
    "            if a != pi[s]:\n",
    "                pi[s] = a\n",
    "                unchanged = False\n",
    "        if unchanged:\n",
    "            return pi\n",
    "\n",
    "def policy_evaluation(pi, U, mdp, k=20):\n",
    "    R, T, gamma = mdp.R, mdp.T, mdp.gamma\n",
    "    for i in range(k):\n",
    "        for s in mdp.states:\n",
    "            U[s] = R(s) + gamma * sum([p * U[s] for (p, s1) in T(s, pi[s])])\n",
    "    return U\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid = [[-0.04, -0.04, -0.04, +1],\n",
    "            [-0.04, None, -0.04, -1],\n",
    "            [-0.04, -0.04, -0.04, -0.04]]\n",
    "    terminals = [(3, 2), (3, 1)]\n",
    "\n",
    "    mdp = GridMDP(grid, terminals)\n",
    "\n",
    "    U = value_iteration(mdp)\n",
    "    pi = best_policy(mdp, U)\n",
    "\n",
    "    print(\"Optimal Policy:\")\n",
    "    print(pi)\n",
    "    print(mdp.to_arrows(pi))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
